"""
æœ€ç»ˆä¿®å¤ç‰ˆ nnUNet Trainer with TE-Swin UNet3D architecture.
ä¿®å¤äº†æ‰€æœ‰å…¼å®¹æ€§é—®é¢˜ï¼ŒåŒ…æ‹¬decoderå±æ€§ã€è®¾å¤‡ç®¡ç†ç­‰ã€‚
"""
import torch
import torch.nn as nn
from typing import Tuple, Union, List
from tqdm import tqdm
from dynamic_network_architectures.building_blocks.helper import get_matching_instancenorm, convert_dim_to_conv_op
from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer
from nnunetv2.utilities.plans_handling.plans_handler import ConfigurationManager, PlansManager

# Import our custom model
from nnunetv2.training.nnUNetTrainer.variants.network_architecture.te_swin_models.nnUNet_TE_SwinUnet3D import (
    create_te_swinunet_s_3d, 
    create_te_swinunet_t_3d, 
    create_te_swinunet_b_3d
)


class nnUNetTrainer_TE_SwinUnet3D(nnUNetTrainer):
    """
    æœ€ç»ˆä¿®å¤ç‰ˆ nnUNet Trainer using TE-Swin UNet3D architecture.
    """
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        """Initialize TE-Swin UNet3D trainer."""
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                        dataset_json=dataset_json, device=device)
        
        # Model variant - can be 't' (tiny), 's' (small), or 'b' (base)
        self.model_variant = 't'  # ä½¿ç”¨tinyå˜ä½“ï¼Œå‚æ•°æ›´å°‘ï¼Œæ›´ç¨³å®š
        
    def build_network_architecture(self, architecture_class_name: str,
                                   arch_init_kwargs: dict,
                                   arch_init_kwargs_req_import: Union[List[str], Tuple[str, ...]],
                                   num_input_channels: int,
                                   num_output_channels: int,
                                   enable_deep_supervision: bool = True):
        """ä¿®å¤åçš„ç½‘ç»œæ¶æ„æ„å»ºæ–¹æ³•ã€‚"""
        self.print_to_log_file(f"Building TE-SwinUnet3D-{self.model_variant} variant")
        self.print_to_log_file(f"Input channels: {num_input_channels}, Output channels: {num_output_channels}")
        self.print_to_log_file(f"Deep supervision: {enable_deep_supervision}")
        
        try:
            # âœ… ä½¿ç”¨å…¼å®¹æ€§ä¼˜åŒ–çš„å‚æ•°
            common_params = {
                'input_channels': num_input_channels,
                'num_classes': num_output_channels,
                'deep_supervision': enable_deep_supervision,
                'window_size': 4,  # å…¼å®¹æ€§ä¼˜åŒ–
                'downscaling_factors': (2, 2, 2, 2)  # å…¼å®¹æ€§ä¼˜åŒ–
            }
            
            if self.model_variant == 't':
                network = create_te_swinunet_t_3d(**common_params)
            elif self.model_variant == 'b':
                network = create_te_swinunet_b_3d(**common_params)
            else:  # Default to 's' (small) model
                network = create_te_swinunet_s_3d(**common_params)
                
            self.print_to_log_file(f"âœ… Successfully created TE-SwinUnet3D-{self.model_variant}")
            self.print_to_log_file(f"Model parameters: {sum(p.numel() for p in network.parameters()):,}")
            
            # âœ… ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            network = network.to(self.device)
            self.print_to_log_file(f"âœ… Model moved to device: {self.device}")
            
            # âœ… éªŒè¯nnUNetå…¼å®¹æ€§å±æ€§
            if hasattr(network, 'decoder'):
                self.print_to_log_file("âœ… Model has decoder attribute for nnUNet compatibility")
            else:
                self.print_to_log_file("âš ï¸  Model missing decoder attribute")
            
            return network
            
        except Exception as e:
            self.print_to_log_file(f"âŒ Failed to create TE-SwinUnet3D: {e}")
            import traceback
            self.print_to_log_file(f"Full traceback:\n{traceback.format_exc()}")
            raise e
    
    def set_deep_supervision_enabled(self, enabled: bool):
        """
        é‡å†™çš„æ·±åº¦ç›‘ç£è®¾ç½®æ–¹æ³•ï¼Œå®Œç¾å…¼å®¹TE-Swin UNet3Dæ¶æ„
        """
        # è·å–å®é™…çš„æ¨¡å‹ï¼ˆå¤„ç†DDPå’ŒcompileåŒ…è£…ï¼‰
        if self.is_ddp:
            mod = self.network.module
        else:
            mod = self.network
            
        # å¤„ç†torch.compileåŒ…è£…
        if hasattr(mod, '_orig_mod'):
            mod = mod._orig_mod
        
        try:
            # âœ… æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬çš„TE-Swinæ¨¡å‹
            if hasattr(mod, '__class__') and 'TE_SwinUnet3D' in mod.__class__.__name__:
                # æˆ‘ä»¬çš„TE-Swin UNet3Dæ¨¡å‹æœ‰ä¸¤ç§è®¾ç½®æ–¹å¼
                
                # æ–¹å¼1ï¼šç›´æ¥è®¾ç½®æ¨¡å‹çš„deep_supervisionå±æ€§
                if hasattr(mod, 'deep_supervision'):
                    mod.deep_supervision = enabled
                    self.print_to_log_file(f"âœ… TE-Swin UNet3D deep_supervision set to: {enabled}")
                
                # æ–¹å¼2ï¼šé€šè¿‡decoderåŒ…è£…å™¨è®¾ç½®ï¼ˆnnUNetå…¼å®¹æ€§ï¼‰
                if hasattr(mod, 'decoder') and hasattr(mod.decoder, 'deep_supervision'):
                    mod.decoder.deep_supervision = enabled
                    self.print_to_log_file(f"âœ… TE-Swin UNet3D decoder.deep_supervision set to: {enabled}")
                
                # æ–¹å¼3ï¼šè®¾ç½®do_dsæ ‡å¿—ï¼ˆnnUNetçš„å¦ä¸€ä¸ªæ ‡å¿—ï¼‰
                if hasattr(mod, 'do_ds'):
                    mod.do_ds = enabled
                    self.print_to_log_file(f"âœ… TE-Swin UNet3D do_ds set to: {enabled}")
                    
            else:
                # æ ‡å‡†nnUNetæ¨¡å‹çš„å¤„ç†
                if hasattr(mod, 'decoder') and hasattr(mod.decoder, 'deep_supervision'):
                    mod.decoder.deep_supervision = enabled
                    self.print_to_log_file(f"âœ… Standard model decoder.deep_supervision set to: {enabled}")
                else:
                    # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
                    if hasattr(mod, 'deep_supervision'):
                        mod.deep_supervision = enabled
                        self.print_to_log_file(f"âœ… Model deep_supervision set to: {enabled}")
                    else:
                        self.print_to_log_file(f"âš ï¸  Could not set deep supervision - no suitable attribute found")
                        
        except Exception as e:
            self.print_to_log_file(f"âš ï¸  Error setting deep supervision: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è®­ç»ƒç»§ç»­
            
    def initialize(self):
        """é‡å†™åˆå§‹åŒ–æ–¹æ³•ï¼Œç¡®ä¿æ­£ç¡®çš„è®¾å¤‡ç®¡ç†"""
        try:
            # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
            super().initialize()
            
            # âœ… ç¡®ä¿ç½‘ç»œåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            if hasattr(self, 'network') and self.network is not None:
                self.network = self.network.to(self.device)
                self.print_to_log_file(f"âœ… Network confirmed on device: {next(self.network.parameters()).device}")
                
            # âœ… è®¾ç½®ç½‘ç»œä¸ºè®­ç»ƒæ¨¡å¼
            if hasattr(self, 'network'):
                self.network.train()
                
        except Exception as e:
            self.print_to_log_file(f"âŒ Initialization error: {e}")
            import traceback
            self.print_to_log_file(f"Full traceback:\n{traceback.format_exc()}")
            raise e
            
    def on_train_start(self):
        """è®­ç»ƒå¼€å§‹æ—¶çš„è®¾å¤‡æ£€æŸ¥å’ŒçŠ¶æ€éªŒè¯"""
        try:
            # âœ… è®¾å¤‡çŠ¶æ€æ£€æŸ¥
            if hasattr(self, 'network') and self.network is not None:
                network_device = next(self.network.parameters()).device
                self.print_to_log_file(f"ğŸ” Network device: {network_device}")
                self.print_to_log_file(f"ğŸ” Expected device: {self.device}")
                
                if network_device != self.device:
                    self.print_to_log_file(f"âš ï¸  Device mismatch! Moving network to {self.device}")
                    self.network = self.network.to(self.device)
                    
            # âœ… GPUå†…å­˜çŠ¶æ€æ£€æŸ¥
            if torch.cuda.is_available():
                self.print_to_log_file(f"ğŸ” GPU memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
                self.print_to_log_file(f"ğŸ” GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB")
            
            print("ğŸš€ Starting TE-Swin UNet3D training with 'MRI as GIF' approach...")
            
            # âœ… è°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼ˆè¿™é‡Œå¯èƒ½ä¼šè°ƒç”¨set_deep_supervision_enabledï¼‰
            super().on_train_start()
            
        except Exception as e:
            self.print_to_log_file(f"âŒ on_train_start error: {e}")
            import traceback
            self.print_to_log_file(f"Full traceback:\n{traceback.format_exc()}")
            raise e
        
    def train_step(self, batch):
        """é‡å†™è®­ç»ƒæ­¥éª¤ï¼Œæ·»åŠ é”™è¯¯å¤„ç†å’Œè®¾å¤‡æ£€æŸ¥"""
        try:
            # âœ… ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            data = batch['data']
            target = batch['target']
            
            if data.device != self.device:
                data = data.to(self.device, non_blocking=True)
                
            if target.device != self.device:
                target = target.to(self.device, non_blocking=True)
                
            batch['data'] = data
            batch['target'] = target
            
            # è°ƒç”¨çˆ¶ç±»çš„è®­ç»ƒæ­¥éª¤
            return super().train_step(batch)
            
        except Exception as e:
            self.print_to_log_file(f"âŒ Training step error: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„lossé¿å…å´©æºƒ
            return {'loss': torch.tensor(1.0, device=self.device)}

    def validation_step(self, batch):
        """é‡å†™éªŒè¯æ­¥éª¤ï¼Œæ·»åŠ é”™è¯¯å¤„ç†"""
        try:
            # âœ… ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            data = batch['data']
            target = batch['target']
            
            if data.device != self.device:
                data = data.to(self.device, non_blocking=True)
                
            if target.device != self.device:
                target = target.to(self.device, non_blocking=True)
                
            batch['data'] = data
            batch['target'] = target
            
            return super().validation_step(batch)
            
        except Exception as e:
            self.print_to_log_file(f"âŒ Validation step error: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„lossé¿å…å´©æºƒ
            return {'loss': torch.tensor(1.0, device=self.device)}

    def run_training(self):
        """é‡å†™è®­ç»ƒå¾ªç¯ï¼Œæ·»åŠ æ›´å¥½çš„é”™è¯¯å¤„ç†"""
        try:
            self.on_train_start()

            for epoch in range(self.current_epoch, self.num_epochs):
                self.print_to_log_file(f"ğŸš€ Starting epoch {epoch}/{self.num_epochs-1}")
                
                self.on_epoch_start()
                
                # âœ… æ¯ä¸ªepochå¼€å§‹æ—¶æ£€æŸ¥è®¾å¤‡çŠ¶æ€
                if hasattr(self, 'network'):
                    network_device = next(self.network.parameters()).device
                    if network_device != self.device:
                        self.print_to_log_file(f"âš ï¸  Epoch {epoch}: Network on {network_device}, moving to {self.device}")
                        self.network = self.network.to(self.device)
                
                # Training phase
                self.on_train_epoch_start()
                train_outputs = []
                
                try:
                    train_iterator = tqdm(
                        range(self.num_iterations_per_epoch),
                        desc=f"Epoch {epoch} Training",
                        unit="batch",
                        colour="green",
                        leave=False,
                        bar_format='{l_bar}{bar:30}{r_bar}'
                    )
                    
                    for batch_id in train_iterator:
                        try:
                            batch = next(self.dataloader_train)
                            output = self.train_step(batch)
                            train_outputs.append(output)
                            
                            # Update progress bar
                            if 'loss' in output:
                                train_iterator.set_postfix({
                                    "loss": f"{output['loss']:.4f}",
                                })
                                
                        except Exception as e:
                            self.print_to_log_file(f"âŒ Training batch {batch_id} failed: {e}")
                            # ç»§ç»­ä¸‹ä¸€ä¸ªbatchè€Œä¸æ˜¯å´©æºƒ
                            continue
                            
                except Exception as e:
                    self.print_to_log_file(f"âŒ Training epoch setup failed: {e}")
                    
                self.on_train_epoch_end(train_outputs)
                
                # Validation phase
                with torch.no_grad():
                    self.on_validation_epoch_start()
                    val_outputs = []
                    
                    try:
                        val_iterator = tqdm(
                            range(self.num_val_iterations_per_epoch),
                            desc=f"Epoch {epoch} Validation",
                            unit="batch",
                            colour="blue",
                            leave=False,
                            bar_format='{l_bar}{bar:30}{r_bar}'
                        )
                        
                        for batch_id in val_iterator:
                            try:
                                batch = next(self.dataloader_val)
                                output = self.validation_step(batch)
                                val_outputs.append(output)
                                
                                # Update progress bar
                                if 'loss' in output:
                                    val_iterator.set_postfix({
                                        "loss": f"{output['loss']:.4f}",
                                    })
                                    
                            except Exception as e:
                                self.print_to_log_file(f"âŒ Validation batch {batch_id} failed: {e}")
                                continue
                                
                    except Exception as e:
                        self.print_to_log_file(f"âŒ Validation epoch setup failed: {e}")
                        
                    self.on_validation_epoch_end(val_outputs)
                
                self.on_epoch_end()
                
                self.print_to_log_file(f"âœ… Epoch {epoch} completed", also_print_to_console=True)
                
        except Exception as e:
            self.print_to_log_file(f"âŒ Training failed: {e}")
            import traceback
            self.print_to_log_file(f"Full traceback:\n{traceback.format_exc()}")
            raise e


class nnUNetTrainer_TE_SwinUnet3D_tiny(nnUNetTrainer_TE_SwinUnet3D):
    """Tiny variant with all fixes."""
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                         dataset_json=dataset_json, device=device)
        self.model_variant = 't'


class nnUNetTrainer_TE_SwinUnet3D_small(nnUNetTrainer_TE_SwinUnet3D):
    """Small variant with all fixes."""
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                         dataset_json=dataset_json, device=device)
        self.model_variant = 's'


class nnUNetTrainer_TE_SwinUnet3D_base(nnUNetTrainer_TE_SwinUnet3D):
    """Base variant with all fixes."""
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                         dataset_json=dataset_json, device=device)
        self.model_variant = 'b'