"""
å®‰å…¨æ— å¾ªç¯å¼•ç”¨çš„ nnUNet Trainer with TE-Swin UNet3D architecture.
ä¸»è¦ä¿®å¤ï¼šç§»é™¤å¯èƒ½å¯¼è‡´å¾ªç¯å¼•ç”¨çš„ä»£ç ï¼Œç®€åŒ–é”™è¯¯å¤„ç†
"""
import torch
import torch.nn as nn
from typing import Tuple, Union, List
from tqdm import tqdm
from dynamic_network_architectures.building_blocks.helper import get_matching_instancenorm, convert_dim_to_conv_op
from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer
from nnunetv2.utilities.plans_handling.plans_handler import ConfigurationManager, PlansManager

# Import our custom model
from nnunetv2.training.nnUNetTrainer.variants.network_architecture.te_swin_models.nnUNet_TE_SwinUnet3D import (
    create_te_swinunet_s_3d, 
    create_te_swinunet_t_3d, 
    create_te_swinunet_b_3d
)


class nnUNetTrainer_TE_SwinUnet3D(nnUNetTrainer):
    """
    å®‰å…¨ç‰ˆæœ¬çš„ nnUNet Trainer using TE-Swin UNet3D architecture.
    """
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        """Initialize TE-Swin UNet3D trainer."""
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                        dataset_json=dataset_json, device=device)
        
        # Model variant - ä½¿ç”¨tinyå˜ä½“ï¼Œå‚æ•°æ›´å°‘ï¼Œæ›´ç¨³å®š
        self.model_variant = 't'
        
    def build_network_architecture(self, architecture_class_name: str,
                                   arch_init_kwargs: dict,
                                   arch_init_kwargs_req_import: Union[List[str], Tuple[str, ...]],
                                   num_input_channels: int,
                                   num_output_channels: int,
                                   enable_deep_supervision: bool = True):
        """ç½‘ç»œæ¶æ„æ„å»ºæ–¹æ³•"""
        self.print_to_log_file(f"Building TE-SwinUnet3D-{self.model_variant} variant")
        self.print_to_log_file(f"Input channels: {num_input_channels}, Output channels: {num_output_channels}")
        self.print_to_log_file(f"Deep supervision: {enable_deep_supervision}")
        
        # âœ… ä½¿ç”¨å…¼å®¹æ€§ä¼˜åŒ–çš„å‚æ•°
        common_params = {
            'input_channels': num_input_channels,
            'num_classes': num_output_channels,
            'deep_supervision': enable_deep_supervision,
            'window_size': 4,  # å…¼å®¹æ€§ä¼˜åŒ–
            'downscaling_factors': (2, 2, 2, 2)  # å…¼å®¹æ€§ä¼˜åŒ–
        }
        
        if self.model_variant == 't':
            network = create_te_swinunet_t_3d(**common_params)
        elif self.model_variant == 'b':
            network = create_te_swinunet_b_3d(**common_params)
        else:  # Default to 's' (small) model
            network = create_te_swinunet_s_3d(**common_params)
            
        self.print_to_log_file(f"âœ… Successfully created TE-SwinUnet3D-{self.model_variant}")
        self.print_to_log_file(f"Model parameters: {sum(p.numel() for p in network.parameters()):,}")
        
        # âœ… ç®€åŒ–çš„è®¾å¤‡ç§»åŠ¨
        current_device = next(network.parameters()).device
        if current_device != self.device:
            self.print_to_log_file(f"Moving model from {current_device} to {self.device}")
            network = network.to(self.device)
            self.print_to_log_file(f"âœ… Model moved to device: {self.device}")
        else:
            self.print_to_log_file(f"âœ… Model already on correct device: {self.device}")
            
        # âœ… éªŒè¯nnUNetå…¼å®¹æ€§å±æ€§
        if hasattr(network, 'decoder'):
            self.print_to_log_file("âœ… Model has decoder attribute for nnUNet compatibility")
        else:
            self.print_to_log_file("âš ï¸  Model missing decoder attribute")
        
        return network
    
    def set_deep_supervision_enabled(self, enabled: bool):
        """æ·±åº¦ç›‘ç£è®¾ç½®æ–¹æ³•"""
        # è·å–å®é™…çš„æ¨¡å‹ï¼ˆå¤„ç†DDPå’ŒcompileåŒ…è£…ï¼‰
        if self.is_ddp:
            mod = self.network.module
        else:
            mod = self.network
            
        # å¤„ç†torch.compileåŒ…è£…
        if hasattr(mod, '_orig_mod'):
            mod = mod._orig_mod
        
        # âœ… å¤šç§æ–¹å¼å°è¯•è®¾ç½®æ·±åº¦ç›‘ç£
        success = False
        
        # æ–¹å¼1ï¼šé€šè¿‡decoderè®¾ç½®ï¼ˆnnUNetæ ‡å‡†æ–¹å¼ï¼‰
        if hasattr(mod, 'decoder') and hasattr(mod.decoder, 'deep_supervision'):
            mod.decoder.deep_supervision = enabled
            self.print_to_log_file(f"âœ… Set via decoder.deep_supervision: {enabled}")
            success = True
        
        # æ–¹å¼2ï¼šç›´æ¥è®¾ç½®æ¨¡å‹å±æ€§
        if hasattr(mod, 'deep_supervision'):
            mod.deep_supervision = enabled
            self.print_to_log_file(f"âœ… Set via model.deep_supervision: {enabled}")
            success = True
        
        # æ–¹å¼3ï¼šè®¾ç½®do_dsæ ‡å¿—
        if hasattr(mod, 'do_ds'):
            mod.do_ds = enabled
            self.print_to_log_file(f"âœ… Set via model.do_ds: {enabled}")
            success = True
            
        if not success:
            self.print_to_log_file(f"âš ï¸  Could not set deep supervision - continuing anyway")
            
    def on_train_start(self):
        """è®­ç»ƒå¼€å§‹æ—¶çš„è®¾å¤‡æ£€æŸ¥"""
        # âœ… åŸºæœ¬çš„è®¾å¤‡çŠ¶æ€æ£€æŸ¥
        if hasattr(self, 'network') and self.network is not None:
            network_device = next(self.network.parameters()).device
            self.print_to_log_file(f"ğŸ” Network device: {network_device}")
            self.print_to_log_file(f"ğŸ” Expected device: {self.device}")
            
            if network_device != self.device:
                self.print_to_log_file(f"âš ï¸  Device mismatch detected!")
                    
        # âœ… GPUå†…å­˜çŠ¶æ€æ£€æŸ¥
        if torch.cuda.is_available():
            self.print_to_log_file(f"ğŸ” GPU memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
            self.print_to_log_file(f"ğŸ” GPU memory reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB")
        
        print("ğŸš€ Starting TE-Swin UNet3D training with 'MRI as GIF' approach...")
        
        # âœ… è°ƒç”¨çˆ¶ç±»æ–¹æ³•
        super().on_train_start()
            
    def train_step(self, batch):
        """ä¿®å¤çš„è®­ç»ƒæ­¥éª¤ - æ­£ç¡®å¤„ç†æ•°æ®æ ¼å¼"""
        # âœ… æ­£ç¡®å¤„ç†æ•°æ® - å¯èƒ½æ˜¯åˆ—è¡¨æˆ–å¼ é‡
        data = batch['data']
        target = batch['target']
        
        # å¤„ç†æ•°æ®è®¾å¤‡ç§»åŠ¨
        if isinstance(data, list):
            data = [d.to(self.device, non_blocking=True) if hasattr(d, 'to') else d for d in data]
        else:
            if hasattr(data, 'device') and data.device != self.device:
                data = data.to(self.device, non_blocking=True)
                
        # å¤„ç†ç›®æ ‡è®¾å¤‡ç§»åŠ¨  
        if isinstance(target, list):
            target = [t.to(self.device, non_blocking=True) if hasattr(t, 'to') else t for t in target]
        else:
            if hasattr(target, 'device') and target.device != self.device:
                target = target.to(self.device, non_blocking=True)
                
        batch['data'] = data
        batch['target'] = target
        
        # è°ƒç”¨çˆ¶ç±»çš„è®­ç»ƒæ­¥éª¤
        return super().train_step(batch)

    def validation_step(self, batch):
        """ä¿®å¤çš„éªŒè¯æ­¥éª¤ - æ­£ç¡®å¤„ç†æ•°æ®æ ¼å¼"""
        # âœ… æ­£ç¡®å¤„ç†æ•°æ® - å¯èƒ½æ˜¯åˆ—è¡¨æˆ–å¼ é‡
        data = batch['data']
        target = batch['target']
        
        # å¤„ç†æ•°æ®è®¾å¤‡ç§»åŠ¨
        if isinstance(data, list):
            data = [d.to(self.device, non_blocking=True) if hasattr(d, 'to') else d for d in data]
        else:
            if hasattr(data, 'device') and data.device != self.device:
                data = data.to(self.device, non_blocking=True)
                
        # å¤„ç†ç›®æ ‡è®¾å¤‡ç§»åŠ¨
        if isinstance(target, list):
            target = [t.to(self.device, non_blocking=True) if hasattr(t, 'to') else t for t in target]
        else:
            if hasattr(target, 'device') and target.device != self.device:
                target = target.to(self.device, non_blocking=True)
                
        batch['data'] = data
        batch['target'] = target
        
        return super().validation_step(batch)


class nnUNetTrainer_TE_SwinUnet3D_tiny(nnUNetTrainer_TE_SwinUnet3D):
    """Tiny variant - æœ€å®‰å…¨çš„é€‰æ‹©"""
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                         dataset_json=dataset_json, device=device)
        self.model_variant = 't'


class nnUNetTrainer_TE_SwinUnet3D_small(nnUNetTrainer_TE_SwinUnet3D):
    """Small variant"""
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                         dataset_json=dataset_json, device=device)
        self.model_variant = 's'


class nnUNetTrainer_TE_SwinUnet3D_base(nnUNetTrainer_TE_SwinUnet3D):
    """Base variant"""
    
    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, 
                 device: torch.device = torch.device('cuda')):
        super().__init__(plans=plans, configuration=configuration, fold=fold, 
                         dataset_json=dataset_json, device=device)
        self.model_variant = 'b'